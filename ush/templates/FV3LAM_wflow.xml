{#

This is a Jinja-enabled Rocoto XML template. It is filled in using the
fill_template.py script, and is done automatically by the
generate_workflow.sh step of preparing a regional workflow configured
experiment.

See README.xml_templating.md for information on using the Templating mechanisms.
-#}
<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE workflow [

<!--
Parameters needed by the job scheduler.
-->
<!ENTITY ACCOUNT       "{{ account }}">
<!ENTITY SCHED         "{{ sched }}">
<!ENTITY QUEUE_DEFAULT "{{ queue_default }}">
<!ENTITY QUEUE_HPSS    "{{ queue_hpss }}">
<!ENTITY QUEUE_FCST    "{{ queue_fcst }}">

<!--
Workflow task names.
-->
<!ENTITY MAKE_GRID_TN      "{{ make_grid_tn }}">
<!ENTITY MAKE_OROG_TN      "{{ make_orog_tn }}">
<!ENTITY MAKE_SFC_CLIMO_TN "{{ make_sfc_climo_tn }}">
<!ENTITY GET_EXTRN_ICS_TN  "{{ get_extrn_ics_tn }}">
<!ENTITY GET_EXTRN_LBCS_TN "{{ get_extrn_lbcs_tn }}">
<!ENTITY MAKE_ICS_TN       "{{ make_ics_tn }}">
<!ENTITY MAKE_LBCS_TN      "{{ make_lbcs_tn }}">
<!ENTITY RUN_FCST_TN       "{{ run_fcst_tn }}">
<!ENTITY RUN_POST_TN       "{{ run_post_tn }}">

<!--
Flags that specify whether to run the preprocessing tasks.
-->
<!ENTITY RUN_TASK_MAKE_GRID      "{{ run_task_make_grid | upper }}">
<!ENTITY RUN_TASK_MAKE_OROG      "{{ run_task_make_orog | upper }}">
<!ENTITY RUN_TASK_MAKE_SFC_CLIMO "{{ run_task_make_sfc_climo | upper }}">

<!--
Number of physical cores per node for the current machine.  This is used
below in the <nodesize> tag, but that tag is not clearly documented.  This
parameter may be unnecessary since each task now has its own variable that
specifies the number of processes per node being used (the PPN_... entities).
-->
<!ENTITY NCORES_PER_NODE "{{ ncores_per_node }}">

<!--
Directories and files.
-->
<!ENTITY JOBSDIR                  "{{ jobsdir }}">
<!ENTITY LOGDIR                   "{{ logdir }}">
<!ENTITY CYCLE_BASEDIR            "{{ cycle_basedir }}">
<!ENTITY GLOBAL_VAR_DEFNS_FP      "{{ global_var_defns_fp }}">
<!ENTITY LOAD_MODULES_RUN_TASK_FP "{{ load_modules_run_task_fp }}">

<!--
Reservation types.  Reservations specify the queue/partition and account
to use for a given task.  The "DEFAULT" reservation type is used for all 
tasks other than GET_EXTRN_ICS_TN, GET_EXTRN_LBCS_TN, and RUN_FCST_TN; 
the "HPSS" type is used for the GET_EXTRN_ICS_TN and GET_EXTRN_LBCS_TN 
tasks; and the "FCST" type is used for the RUN_FCST_TN task.
-->

{%- if partition_default is not none %}
<!ENTITY RSRV_DEFAULT "<account>&ACCOUNT;</account><queue>&QUEUE_DEFAULT;</queue><partition>{{ partition_default }}</partition>">
{%- else %}
<!ENTITY RSRV_DEFAULT "<account>&ACCOUNT;</account><queue>&QUEUE_DEFAULT;</queue>">
{%- endif %}
{%- if partition_hpss is not none %}
<!ENTITY RSRV_HPSS    "<account>&ACCOUNT;</account><queue>&QUEUE_HPSS;</queue><partition>{{ partition_hpss }}</partition>">
{%- else %}
<!ENTITY RSRV_HPSS    "<account>&ACCOUNT;</account><queue>&QUEUE_HPSS;</queue>">
{%- endif %}
{%- if partition_fcst is not none %}
<!ENTITY RSRV_FCST    "<account>&ACCOUNT;</account><queue>&QUEUE_FCST;</queue><partition>{{ partition_fcst }}</partition>">
{%- else %}
<!ENTITY RSRV_FCST    "<account>&ACCOUNT;</account><queue>&QUEUE_FCST;</queue>">
{%- endif %}

]>

<workflow realtime="F" scheduler="&SCHED;" cyclethrottle="20">
{# Double quotes are required inside the strftime! Expect an error from reading the template if using single quotes. #}
  <cycledef group="at_start">{{ cdate_first_cycl.strftime("%M %H %d %m %Y *") }}</cycledef>
{% for c in cycl_hrs %}
  <cycledef group="forecast">
  {%- set cdate_first=date_first_cycl ~ c ~ "00" -%}
  {%- set cdate_last=date_last_cycl ~ c ~ "00" -%}
  {{- cdate_first ~ " " ~ cdate_last ~ " " ~ cycl_freq -}}
  </cycledef>
{%- endfor %}

  <log>
    <cyclestr>&LOGDIR;/FV3LAM_wflow.log</cyclestr>
  </log>

<!-- 
The following command works to call the J-job for a given task (in this
case the MAKE_GRID_TN task) if in the script LOAD_MODULES_RUN_TASK_FP we 
do NOT call exec to run the J-job.  The command first sources the script
LOAD_MODULES_RUN_TASK_FP and then runs the J-job, so it is simpler than
calling exec and thus preferred if NCO accepts it.  Note that the portion
of the command that sources LOAD_MODULES_RUN_TASK_FP also passes an 
argument to it (the argument being the name of the task).  This works in
bash but it probably won't work in sh.

If this method is acceptable to NCO, then for clarity maybe we can
source LOAD_MODULES_RUN_TASK_FP within the J-job instead of here since
we are already sourcing other files in the J-job anyway.
-->
<!--
    <command>{ . &LOAD_MODULES_RUN_TASK_FP; "&MAKE_GRID_TN;";
               &JOBSDIR;/JREGIONAL_MAKE_GRID;
             }</command>
-->
<!--
The following command works if we call exec in LOAD_MODULES_RUN_TASK_FP
to run the J-job.  This passes the J-job script as the second argument
to LOAD_MODULES_RUN_TASK_FP (the first argument is the task name).  The
J-job then uses exec to run the J-job (while also terminating the LOAD_-
MODULES_RUN_TASK_FP script.
-->

{% if run_task_make_grid %}
<!--
************************************************************************
************************************************************************
-->
  <task name="&MAKE_GRID_TN;" cycledefs="at_start" maxtries="{{ maxtries_make_grid }}">

    &RSRV_DEFAULT;
    <command>&LOAD_MODULES_RUN_TASK_FP; "&MAKE_GRID_TN;" "&JOBSDIR;/JREGIONAL_MAKE_GRID"</command>
  {% if machine in ["WCOSS_DELL_P3", "WCOSS_CRAY"]  %}
    <nodes>{{ nnodes_make_grid }}:ppn=1</nodes>
  {% else %}
    <nodes>{{ nnodes_make_grid }}:ppn={{ ppn_make_grid }}</nodes>
  {% endif %}
    <walltime>{{ wtime_make_grid }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&MAKE_GRID_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&MAKE_GRID_TN;.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>

  </task>
{% endif %}

{% if run_task_make_orog %}
<!--
************************************************************************
************************************************************************
-->
  <task name="&MAKE_OROG_TN;" cycledefs="at_start" maxtries="{{ maxtries_make_orog }}">

    &RSRV_DEFAULT;
    <command>&LOAD_MODULES_RUN_TASK_FP; "&MAKE_OROG_TN;" "&JOBSDIR;/JREGIONAL_MAKE_OROG"</command>
  {% if machine in ["WCOSS_DELL_P3", "WCOSS_CRAY"]  %}
    <nodes>{{ nnodes_make_orog }}:ppn=1</nodes>
  {% else %}
    <nodes>{{ nnodes_make_orog }}:ppn={{ ppn_make_orog }}</nodes>
  {% endif %}
    <walltime>{{ wtime_make_orog }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&MAKE_OROG_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&MAKE_OROG_TN;.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>

    <dependency>
      <or>
<!--        <taskdep task="make_grid"/> -->
        <datadep age="00:00:00:05">&LOGDIR;/&MAKE_GRID_TN;_task_complete.txt</datadep>
        <streq><left>&RUN_TASK_MAKE_GRID;</left><right>FALSE</right></streq>
      </or>
    </dependency>

  </task>
{% endif %}

{% if run_task_make_sfc_climo %}
<!--
************************************************************************
************************************************************************
-->
  <task name="&MAKE_SFC_CLIMO_TN;" cycledefs="at_start" maxtries="{{ maxtries_make_sfc_climo }}">

    &RSRV_DEFAULT;
    <command>&LOAD_MODULES_RUN_TASK_FP; "&MAKE_SFC_CLIMO_TN;" "&JOBSDIR;/JREGIONAL_MAKE_SFC_CLIMO"</command>
    <nodes>{{ nnodes_make_sfc_climo }}:ppn={{ ppn_make_sfc_climo }}</nodes>
    <walltime>{{ wtime_make_sfc_climo }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&MAKE_SFC_CLIMO_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&MAKE_SFC_CLIMO_TN;.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>

    <dependency>
      <and>
        <or>
<!--          <taskdep task="&MAKE_GRID_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_GRID_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_GRID;</left><right>FALSE</right></streq>
        </or>
        <or>
<!--          <taskdep task="&MAKE_OROG_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_OROG_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_OROG;</left><right>FALSE</right></streq>
        </or>
      </and>
    </dependency>

  </task>
{% endif %}

<!--
************************************************************************
************************************************************************
-->
  <task name="&GET_EXTRN_ICS_TN;" maxtries="{{ maxtries_get_extrn_ics }}">

    &RSRV_HPSS;
  {% if machine in ["WCOSS_CRAY"] %}
    <shared/>
  {% endif %}
    <command>&LOAD_MODULES_RUN_TASK_FP; "&GET_EXTRN_ICS_TN;" "&JOBSDIR;/JREGIONAL_GET_EXTRN_MDL_FILES"</command>
  {% if machine in ["WCOSS_DELL_P3"] %}
    <memory>2048M</memory><native>-R affinity[core]</native>
  {% endif %}
    <nodes>{{ nnodes_get_extrn_ics }}:ppn={{ ppn_get_extrn_ics }}</nodes>
    <walltime>{{ wtime_get_extrn_ics }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&GET_EXTRN_ICS_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&GET_EXTRN_ICS_TN;_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
    <envar><name>EXTRN_MDL_NAME</name><value>{{ extrn_mdl_name_ics }}</value></envar>
    <envar><name>ICS_OR_LBCS</name><value>ICS</value></envar>

  </task>
<!--
************************************************************************
************************************************************************
-->
  <task name="&GET_EXTRN_LBCS_TN;" maxtries="{{ maxtries_get_extrn_lbcs }}">

    &RSRV_HPSS;
  {% if machine in ["WCOSS_CRAY"] %}
    <shared/>
  {% endif %}
    <command>&LOAD_MODULES_RUN_TASK_FP; "&GET_EXTRN_LBCS_TN;" "&JOBSDIR;/JREGIONAL_GET_EXTRN_MDL_FILES"</command>
  {% if machine in ["WCOSS_DELL_P3"] %}
    <memory>2048M</memory><native>-R affinity[core]</native>
  {% endif %}
    <nodes>{{ nnodes_get_extrn_lbcs }}:ppn={{ ppn_get_extrn_lbcs }}</nodes>
    <walltime>{{ wtime_get_extrn_lbcs }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&GET_EXTRN_LBCS_TN;</jobname>
    <join><cyclestr>&LOGDIR;/&GET_EXTRN_LBCS_TN;_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
    <envar><name>EXTRN_MDL_NAME</name><value>{{ extrn_mdl_name_lbcs }}</value></envar>
    <envar><name>ICS_OR_LBCS</name><value>LBCS</value></envar>

  </task>
<!--
************************************************************************
************************************************************************
-->
{%- if do_ensemble %}
  <metatask name="run_ensemble">

    <var name="{{ ensmem_indx_name }}">
{%- for m in range(1, num_ens_members+1) -%}
  {%- set fmtstr=" %0"~ndigits_ensmem_names~"d" -%}
  {{- fmtstr%m -}}
{%- endfor %} </var>
{%- endif %}

  <task name="&MAKE_ICS_TN;{{ uscore_ensmem_name }}" maxtries="{{ maxtries_make_ics }}">

    &RSRV_DEFAULT;
    <command>&LOAD_MODULES_RUN_TASK_FP; "&MAKE_ICS_TN;" "&JOBSDIR;/JREGIONAL_MAKE_ICS"</command>
    <nodes>{{ nnodes_make_ics }}:ppn={{ ppn_make_ics }}</nodes>
    <walltime>{{ wtime_make_ics }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&MAKE_ICS_TN;{{ uscore_ensmem_name }}</jobname>
    <join><cyclestr>&LOGDIR;/&MAKE_ICS_TN;{{ uscore_ensmem_name }}_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
    <envar><name>SLASH_ENSMEM_SUBDIR</name><value><cyclestr>{{ slash_ensmem_subdir }}</cyclestr></value></envar>

    <dependency>
      <and>
        <taskdep task="&GET_EXTRN_ICS_TN;"/>
        <or>
<!--          <taskdep task="&MAKE_GRID_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_GRID_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_GRID;</left><right>FALSE</right></streq>
        </or>
        <or>
<!--          <taskdep task="&MAKE_OROG_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_OROG_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_OROG;</left><right>FALSE</right></streq>
        </or>
        <or>
<!--          <taskdep task="&MAKE_SFC_CLIMO_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_SFC_CLIMO_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_SFC_CLIMO;</left><right>FALSE</right></streq>
        </or>
      </and>
    </dependency>

  </task>
<!--
************************************************************************
************************************************************************
-->
  <task name="&MAKE_LBCS_TN;{{ uscore_ensmem_name }}" maxtries="{{ maxtries_make_lbcs }}">

    &RSRV_DEFAULT;
    <command>&LOAD_MODULES_RUN_TASK_FP; "&MAKE_LBCS_TN;" "&JOBSDIR;/JREGIONAL_MAKE_LBCS"</command>
    <nodes>{{ nnodes_make_lbcs }}:ppn={{ ppn_make_lbcs }}</nodes>
    <walltime>{{ wtime_make_lbcs }}</walltime>
    <nodesize>&NCORES_PER_NODE;</nodesize>
    <jobname>&MAKE_LBCS_TN;{{ uscore_ensmem_name }}</jobname>
    <join><cyclestr>&LOGDIR;/&MAKE_LBCS_TN;{{ uscore_ensmem_name }}_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
    <envar><name>SLASH_ENSMEM_SUBDIR</name><value><cyclestr>{{ slash_ensmem_subdir }}</cyclestr></value></envar>

    <dependency>
      <and>
        <taskdep task="&GET_EXTRN_LBCS_TN;"/>
        <or>
<!--          <taskdep task="&MAKE_GRID_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_GRID_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_GRID;</left><right>FALSE</right></streq>
        </or>
        <or>
<!--          <taskdep task="&MAKE_OROG_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_OROG_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_OROG;</left><right>FALSE</right></streq>
        </or>
        <or>
<!--          <taskdep task="&MAKE_SFC_CLIMO_TN;"/> -->
          <datadep age="00:00:00:05">&LOGDIR;/&MAKE_SFC_CLIMO_TN;_task_complete.txt</datadep>
          <streq><left>&RUN_TASK_MAKE_SFC_CLIMO;</left><right>FALSE</right></streq>
        </or>
      </and>
    </dependency>

  </task>
<!--
************************************************************************
************************************************************************
-->
  <task name="&RUN_FCST_TN;{{ uscore_ensmem_name }}" maxtries="{{ maxtries_run_fcst }}">

    &RSRV_FCST;
    <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_FCST_TN;" "&JOBSDIR;/JREGIONAL_RUN_FCST"</command>
  {% if machine in ["JET", "HERA"]  %}
    <cores>{{ ncores_run_fcst }}</cores>
    <native>{{ native_run_fcst }}</native>
  {% else %}
    <nodes>{{ nnodes_run_fcst }}:ppn={{ ppn_run_fcst }}</nodes>
    <nodesize>&NCORES_PER_NODE;</nodesize>
  {% endif %}
    <walltime>{{ wtime_run_fcst }}</walltime>
    <jobname>&RUN_FCST_TN;{{ uscore_ensmem_name }}</jobname>
    <join><cyclestr>&LOGDIR;/&RUN_FCST_TN;{{ uscore_ensmem_name }}_@Y@m@d@H.log</cyclestr></join>

    <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
    <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
    <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
    <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
    <envar><name>SLASH_ENSMEM_SUBDIR</name><value><cyclestr>{{ slash_ensmem_subdir }}</cyclestr></value></envar>
    <envar><name>ENSMEM_INDX</name><value><cyclestr>#{{ ensmem_indx_name }}#</cyclestr></value></envar>

    <dependency>
      <and>
        <taskdep task="&MAKE_ICS_TN;{{ uscore_ensmem_name }}"/>
        <taskdep task="&MAKE_LBCS_TN;{{ uscore_ensmem_name }}"/>
      </and>
    </dependency>

  </task>
<!--
************************************************************************
************************************************************************
-->
  {% if sub_hourly_post %}
<!--
Define the post-processing task for first model output time.  The forecast 
hour corresponding to this output time is zero (formatted to the appropriate
number of digits), and the corresponding forecast minute is the first model 
time step dt_atmos, i.e. it is not zero.  This is because FV3 is designed 
such that its first output file contains fields at the first time step.  
It is for this reason that this task is not rolled into the metatask(s) 
further below.

Note that we wrap this task in a metatask in order to be able to declare
and use the variables fhr and fmin.  This allows the block of code inside
the <task> tag (except for the dependencies) to be identical to the ones 
later below for other output times.
-->
  <metatask>

    <var name="fhr">000</var>
    <var name="fmin">00</var>
    <task name="&RUN_POST_TN;{{ uscore_ensmem_name }}_f#fhr##fmin#" maxtries="{{ maxtries_run_post }}">

      &RSRV_DEFAULT;
      <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_POST_TN;" "&JOBSDIR;/JREGIONAL_RUN_POST"</command>
      <nodes>{{ nnodes_run_post }}:ppn={{ ppn_run_post }}</nodes>
      <walltime>{{ wtime_run_post }}</walltime>
      <nodesize>&NCORES_PER_NODE;</nodesize>
      <jobname>&RUN_POST_TN;{{ uscore_ensmem_name }}_f#fhr##fmin#</jobname>
      <join><cyclestr>&LOGDIR;/&RUN_POST_TN;{{ uscore_ensmem_name }}_f#fhr##fmin#_@Y@m@d@H.log</cyclestr></join>

      <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
      <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
      <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
      <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
      <envar><name>SLASH_ENSMEM_SUBDIR</name><value><cyclestr>{{ slash_ensmem_subdir }}</cyclestr></value></envar>
      <envar><name>cyc</name><value><cyclestr>@H</cyclestr></value></envar>
      <envar><name>fhr</name><value>#fhr#</value></envar>
      <envar><name>fmn</name><value>#fmin#</value></envar>

{#
Note that because the forecast minutes and seconds corresponding to the
first model output time are not exactly zero, we use the jinja template
variable first_fv3_file_tstr instead of fhr and fmin to form the file 
names in the dependencies.
#}
      <dependency>
        <or>
          <taskdep task="&RUN_FCST_TN;{{ uscore_ensmem_name }}"/>
          <and>
            <datadep age="05:00"><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H{{ slash_ensmem_subdir }}/dynf{{ first_fv3_file_tstr }}.nc</cyclestr></datadep>
            <datadep age="05:00"><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H{{ slash_ensmem_subdir }}/phyf{{ first_fv3_file_tstr }}.nc</cyclestr></datadep>
          </and>
        </or>
      </dependency>

    </task>

  </metatask>

<!--
Define the post-processing tasks for the second through last output minutes
of the first output hour (which is zero).  We use two metatasks for this.
The inner one is needed to loop over the minutes, and the outer one is 
used in order to be able to declare and use the variable fhr.  Use of this
variable (along with the fmin variable in the inner metatask) allows the 
block of code inside the <task> tag to be identical to the ones later below 
for other output times.
-->
  <metatask name="&RUN_POST_TN;{{ uscore_ensmem_name }}_f000">

    <var name="fhr">000</var>
    <metatask>

      <var name="fmin">{% for min in range(delta_min, 60, delta_min) %}{{ " %02d" % min }}{% endfor %}</var>
      <task name="&RUN_POST_TN;{{ uscore_ensmem_name }}_f#fhr##fmin#" maxtries="{{ maxtries_run_post }}">

        &RSRV_DEFAULT;
        <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_POST_TN;" "&JOBSDIR;/JREGIONAL_RUN_POST"</command>
        <nodes>{{ nnodes_run_post }}:ppn={{ ppn_run_post }}</nodes>
        <walltime>{{ wtime_run_post }}</walltime>
        <nodesize>&NCORES_PER_NODE;</nodesize>
        <jobname>&RUN_POST_TN;{{ uscore_ensmem_name }}_f#fhr##fmin#</jobname>
        <join><cyclestr>&LOGDIR;/&RUN_POST_TN;{{ uscore_ensmem_name }}_f#fhr##fmin#_@Y@m@d@H.log</cyclestr></join>

        <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
        <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
        <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
        <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
        <envar><name>SLASH_ENSMEM_SUBDIR</name><value><cyclestr>{{ slash_ensmem_subdir }}</cyclestr></value></envar>
        <envar><name>cyc</name><value><cyclestr>@H</cyclestr></value></envar>
        <envar><name>fhr</name><value>#fhr#</value></envar>
        <envar><name>fmn</name><value>#fmin#</value></envar>

        <dependency>
          <or>
            <taskdep task="&RUN_FCST_TN;{{ uscore_ensmem_name }}"/>
            <and>
              <datadep age="05:00"><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H{{ slash_ensmem_subdir }}/dynf#fhr#:#fmin#:00.nc</cyclestr></datadep>
              <datadep age="05:00"><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H{{ slash_ensmem_subdir }}/phyf#fhr#:#fmin#:00.nc</cyclestr></datadep>
            </and>
          </or>
        </dependency>

      </task>

    </metatask>

  </metatask>
  {% endif %}

  <metatask name="&RUN_POST_TN;{{ uscore_ensmem_name }}">
  {% if sub_hourly_post %}
<!--
Define the post-processing tasks for the second through next-to-last model
output hours (and all output minutes for each such hour).  
-->
    <var name="fhr">{% for h in range(1, fcst_len_hrs) %}{{ " %03d" % h }}{% endfor %}</var>
    <metatask>
      <var name="fmin">{% for min in range(0, 60, delta_min) %}{{ " %02d" % min }}{% endfor %}</var>
  {% else %}
<!--
Define the post-processing tasks for each model output hour.  Note that
only one metatask is needed for this purpose (the inner one that loops 
over the hours), but we use two metatasks in order to be able to use the 
variable fmin, which here is always set to zero.  Use of this variable 
(along with the fhr variable in the inner metatask) allows the block of 
code inside the <task> tag to be identical to the case in which subhourly 
post-processing is performed (i.e. the case in which the minutes are not 
always zero).
-->
    <var name="fhr">{% for h in range(0, fcst_len_hrs+1) %}{{ " %03d" % h }}{% endfor %}</var>
    <metatask>
      <var name="fmin">00</var>
  {% endif %}
      <task name="&RUN_POST_TN;{{ uscore_ensmem_name }}_f#fhr##fmin#" maxtries="{{ maxtries_run_post }}">

        &RSRV_DEFAULT;
        <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_POST_TN;" "&JOBSDIR;/JREGIONAL_RUN_POST"</command>
        <nodes>{{ nnodes_run_post }}:ppn={{ ppn_run_post }}</nodes>
        <walltime>{{ wtime_run_post }}</walltime>
        <nodesize>&NCORES_PER_NODE;</nodesize>
        <jobname>&RUN_POST_TN;{{ uscore_ensmem_name }}_f#fhr##fmin#</jobname>
        <join><cyclestr>&LOGDIR;/&RUN_POST_TN;{{ uscore_ensmem_name }}_f#fhr##fmin#_@Y@m@d@H.log</cyclestr></join>

        <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
        <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
        <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
        <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
        <envar><name>SLASH_ENSMEM_SUBDIR</name><value><cyclestr>{{ slash_ensmem_subdir }}</cyclestr></value></envar>
        <envar><name>cyc</name><value><cyclestr>@H</cyclestr></value></envar>
        <envar><name>fhr</name><value>#fhr#</value></envar>
        <envar><name>fmn</name><value>#fmin#</value></envar>

        <dependency>
          <or>
            <taskdep task="&RUN_FCST_TN;{{ uscore_ensmem_name }}"/>
            <and>
            {% if sub_hourly_post %}
              <datadep age="05:00"><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H{{ slash_ensmem_subdir }}/dynf#fhr#:#fmin#:00.nc</cyclestr></datadep>
              <datadep age="05:00"><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H{{ slash_ensmem_subdir }}/phyf#fhr#:#fmin#:00.nc</cyclestr></datadep>
            {% else %}
              <datadep age="05:00"><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H{{ slash_ensmem_subdir }}/dynf#fhr#.nc</cyclestr></datadep>
              <datadep age="05:00"><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H{{ slash_ensmem_subdir }}/phyf#fhr#.nc</cyclestr></datadep>
            {% endif %}
            </and>
          </or>
        </dependency>

      </task>

    </metatask>

  </metatask>

{% if sub_hourly_post %}
<!--
Define the post-processing task for the last model output time.  The 
forecast hour corresponding to this output time is the length of the 
forecast (assuming it is specified in integer hours), and the corresponding 
minute is 0.  This task cannot be included in the metatask above because 
for a given hour, the latter loops over all the valid output minutes, 
whereas for this last hour, only the first minute must be considered.

Note that we wrap this task in a metatask in order to be able to declare
and use the variables fhr and fmin.  This allows the block of code inside
the <task> tag to be identical to the ones above for other output times.
-->
  <metatask>

    <var name="fhr">{{ "%03d" % fcst_len_hrs }}</var>
    <var name="fmin">00</var>
    <task name="&RUN_POST_TN;{{ uscore_ensmem_name }}_f#fhr##fmin#" maxtries="{{ maxtries_run_post }}">

      &RSRV_DEFAULT;
      <command>&LOAD_MODULES_RUN_TASK_FP; "&RUN_POST_TN;" "&JOBSDIR;/JREGIONAL_RUN_POST"</command>
      <nodes>{{ nnodes_run_post }}:ppn={{ ppn_run_post }}</nodes>
      <walltime>{{ wtime_run_post }}</walltime>
      <nodesize>&NCORES_PER_NODE;</nodesize>
      <jobname>&RUN_POST_TN;{{ uscore_ensmem_name }}_f#fhr##fmin#</jobname>
      <join><cyclestr>&LOGDIR;/&RUN_POST_TN;{{ uscore_ensmem_name }}_f#fhr##fmin#_@Y@m@d@H.log</cyclestr></join>

      <envar><name>GLOBAL_VAR_DEFNS_FP</name><value>&GLOBAL_VAR_DEFNS_FP;</value></envar>
      <envar><name>PDY</name><value><cyclestr>@Y@m@d</cyclestr></value></envar>
      <envar><name>CDATE</name><value><cyclestr>@Y@m@d@H</cyclestr></value></envar>
      <envar><name>CYCLE_DIR</name><value><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H</cyclestr></value></envar>
      <envar><name>SLASH_ENSMEM_SUBDIR</name><value><cyclestr>{{ slash_ensmem_subdir }}</cyclestr></value></envar>
      <envar><name>cyc</name><value><cyclestr>@H</cyclestr></value></envar>
      <envar><name>fhr</name><value>#fhr#</value></envar>
      <envar><name>fmn</name><value>#fmin#</value></envar>

      <dependency>
        <or>
          <taskdep task="&RUN_FCST_TN;{{ uscore_ensmem_name }}"/>
          <and>
            <datadep age="05:00"><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H{{ slash_ensmem_subdir }}/dynf#fhr#:#fmin#:00.nc</cyclestr></datadep>
            <datadep age="05:00"><cyclestr>&CYCLE_BASEDIR;/@Y@m@d@H{{ slash_ensmem_subdir }}/phyf#fhr#:#fmin#:00.nc</cyclestr></datadep>
          </and>
        </or>
      </dependency>

    </task>

  </metatask>
{% endif %}

{% if do_ensemble %}
  </metatask>
{% endif %}

</workflow>
